{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDRABNLXGLvL"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGFrujYuGLvR"
   },
   "outputs": [],
   "source": [
    "X = np.array(([2,9],[1,5],[3,6]),dtype=float)\n",
    "y = np.array(([92],[86],[89]),dtype=float)\n",
    "X = X/np.amax(X,axis=0) \n",
    "y = y/100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NASHqtgBGLvR"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self):\n",
    "        self.inputsize=2\n",
    "        self.outputsize=1\n",
    "        self.hiddensize=3\n",
    "        self.w1 = np.random.rand(self.inputsize, self.hiddensize) \n",
    "        self.w2 = np.random.rand(self.hiddensize, self.outputsize)\n",
    "    def feedforward(self, X):\n",
    "        self.z = np.dot(X,self.w1) \n",
    "        self.z2 = self.sigmoid(self.z)\n",
    "        self.z3 = np.dot(self.z2,self.w2) \n",
    "        output = self.sigmoid(self.z3)\n",
    "        return output\n",
    "    def sigmoid(self,s,deriv=False):\n",
    "        if(deriv == True):\n",
    "            return s * (1-s)\n",
    "        return 1/(1+np.exp(-s))\n",
    "    def backward(self,X,y,output):\n",
    "        self.output_error = y -output\n",
    "        self.output_delta = self.output_error * self.sigmoid(output, deriv=True)\n",
    "        self.z2_error = self.output_delta.dot(self.w2.T)\n",
    "        self.z2_delta = self.z2_error * self.sigmoid(self.z2,deriv=True)\n",
    "        self.w1 += X.T.dot(self.z2_delta)\n",
    "        self.w2 += self.z2.T.dot(self.output_delta)\n",
    "    def train(self,X,y):\n",
    "        output = self.feedforward(X)\n",
    "        self.backward(X,y,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2btzSJ3hGLvS",
    "outputId": "e573487c-161a-40ad-d832-1e176835534b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.06739445719697605\n",
      "Loss: 0.0002238025190139968\n",
      "Loss: 0.00022031793726880078\n",
      "Loss: 0.00021728288788836546\n",
      "Loss: 0.00021437535229167393\n",
      "Loss: 0.00021158794620805232\n",
      "Loss: 0.00020891386373851213\n",
      "Loss: 0.00020634679427165574\n",
      "Loss: 0.0002038808788525547\n",
      "Loss: 0.00020151067099052566\n",
      "Loss: 0.00019923110142478685\n",
      "Loss: 0.00019703744639605302\n",
      "Loss: 0.00019492529902893048\n",
      "Loss: 0.0001928905434795108\n",
      "Loss: 0.0001909293315450827\n",
      "Loss: 0.000189038061469839\n",
      "Loss: 0.00018721335871245076\n",
      "Loss: 0.00018545205846908622\n",
      "Loss: 0.00018375118976974894\n",
      "Loss: 0.00018210796098670477\n",
      "Loss: 0.0001805197466123616\n",
      "Loss: 0.00017898407517986394\n",
      "Loss: 0.0001774986182139005\n",
      "Loss: 0.00017606118011155732\n",
      "Loss: 0.0001746696888638886\n",
      "Loss: 0.00017332218753853663\n",
      "Loss: 0.0001720168264521088\n",
      "Loss: 0.00017075185596851692\n",
      "Loss: 0.00016952561986611274\n",
      "Loss: 0.00016833654922221938\n",
      "Loss: 0.0001671831567689866\n",
      "Loss: 0.00016606403167893817\n",
      "Loss: 0.00016497783474284938\n",
      "Loss: 0.00016392329390611164\n",
      "Loss: 0.00016289920013313737\n",
      "Loss: 0.00016190440357211175\n",
      "Loss: 0.00016093780999519203\n",
      "Loss: 0.0001599983774913905\n",
      "Loss: 0.0001590851133916724\n",
      "Loss: 0.00015819707140749827\n",
      "Loss: 0.0001573333489658611\n",
      "Loss: 0.00015649308472532559\n",
      "Loss: 0.00015567545625896328\n",
      "Loss: 0.00015487967789130387\n",
      "Loss: 0.00015410499867756934\n",
      "Loss: 0.00015335070051441713\n",
      "Loss: 0.00015261609637238943\n",
      "Loss: 0.00015190052864102842\n",
      "Loss: 0.00015120336757843577\n",
      "Loss: 0.00015052400985768205\n",
      "Loss: 0.00014986187720309935\n",
      "Loss: 0.00014921641511009994\n",
      "Loss: 0.0001485870916425931\n",
      "Loss: 0.00014797339630262537\n",
      "Loss: 0.00014737483896722246\n",
      "Loss: 0.00014679094888785397\n",
      "Loss: 0.00014622127374826335\n",
      "Loss: 0.00014566537877674105\n",
      "Loss: 0.00014512284590922043\n",
      "Loss: 0.00014459327299985034\n",
      "Loss: 0.00014407627307590912\n",
      "Loss: 0.00014357147363423787\n",
      "Loss: 0.00014307851597646843\n",
      "Loss: 0.00014259705458063884\n",
      "Loss: 0.0001421267565068238\n",
      "Loss: 0.0001416673008347423\n",
      "Loss: 0.00014121837813126786\n",
      "Loss: 0.00014077968994607925\n",
      "Loss: 0.00014035094833367282\n",
      "Loss: 0.00013993187540019514\n",
      "Loss: 0.00013952220287357967\n",
      "Loss: 0.00013912167169558067\n",
      "Loss: 0.0001387300316344678\n",
      "Loss: 0.00013834704091712465\n",
      "Loss: 0.0001379724658794496\n",
      "Loss: 0.00013760608063398576\n",
      "Loss: 0.00013724766675381019\n",
      "Loss: 0.00013689701297178172\n",
      "Loss: 0.00013655391489421695\n",
      "Loss: 0.00013621817472826353\n",
      "Loss: 0.0001358896010221759\n",
      "Loss: 0.0001355680084177814\n",
      "Loss: 0.00013525321741449296\n",
      "Loss: 0.00013494505414420643\n",
      "Loss: 0.00013464335015657267\n",
      "Loss: 0.0001343479422139784\n",
      "Loss: 0.00013405867209583528\n",
      "Loss: 0.00013377538641161913\n",
      "Loss: 0.00013349793642221795\n",
      "Loss: 0.0001332261778691856\n",
      "Loss: 0.00013295997081144803\n",
      "Loss: 0.0001326991794691225\n",
      "Loss: 0.0001324436720740762\n",
      "Loss: 0.00013219332072687937\n",
      "Loss: 0.0001319480012598344\n",
      "Loss: 0.00013170759310579452\n",
      "Loss: 0.00013147197917247894\n",
      "Loss: 0.00013124104572199912\n",
      "Loss: 0.00013101468225536808\n",
      "Loss: 0.00013079278140175335\n",
      "Loss: 0.0001305752388122203\n",
      "Loss: 0.00013036195305777314\n",
      "Loss: 0.00013015282553149494\n",
      "Loss: 0.00012994776035458335\n",
      "Loss: 0.00012974666428608865\n",
      "Loss: 0.00012954944663622685\n",
      "Loss: 0.00012935601918305617\n",
      "Loss: 0.00012916629609238697\n",
      "Loss: 0.0001289801938407625\n",
      "Loss: 0.0001287976311414203\n",
      "Loss: 0.0001286185288730249\n",
      "Loss: 0.00012844281001110565\n",
      "Loss: 0.00012827039956208054\n",
      "Loss: 0.00012810122449969923\n",
      "Loss: 0.00012793521370387976\n",
      "Loss: 0.00012777229790174975\n",
      "Loss: 0.0001276124096108825\n",
      "Loss: 0.00012745548308456162\n",
      "Loss: 0.00012730145425903202\n",
      "Loss: 0.0001271502607026416\n",
      "Loss: 0.00012700184156678462\n",
      "Loss: 0.00012685613753859117\n",
      "Loss: 0.00012671309079528213\n",
      "Loss: 0.00012657264496010042\n",
      "Loss: 0.0001264347450597942\n",
      "Loss: 0.00012629933748356187\n",
      "Loss: 0.00012616636994340402\n",
      "Loss: 0.00012603579143582173\n",
      "Loss: 0.0001259075522048344\n",
      "Loss: 0.00012578160370621742\n",
      "Loss: 0.00012565789857297327\n",
      "Loss: 0.00012553639058191158\n",
      "Loss: 0.00012541703462138135\n",
      "Loss: 0.0001252997866600295\n",
      "Loss: 0.00012518460371660852\n",
      "Loss: 0.0001250714438307591\n",
      "Loss: 0.000124960266034735\n",
      "Loss: 0.00012485103032605467\n",
      "Loss: 0.00012474369764100984\n",
      "Loss: 0.00012463822982904023\n",
      "Loss: 0.00012453458962790657\n",
      "Loss: 0.00012443274063965066\n",
      "Loss: 0.0001243326473073164\n",
      "Loss: 0.0001242342748923958\n",
      "Loss: 0.00012413758945296405\n",
      "Loss: 0.0001240425578225151\n",
      "Loss: 0.00012394914758941325\n",
      "Loss: 0.0001238573270770254\n",
      "Loss: 0.0001237670653243966\n",
      "Loss: 0.00012367833206757258\n",
      "Loss: 0.00012359109772142887\n",
      "Loss: 0.00012350533336209495\n",
      "Loss: 0.00012342101070987344\n",
      "Loss: 0.00012333810211267413\n",
      "Loss: 0.00012325658052994549\n",
      "Loss: 0.0001231764195170766\n",
      "Loss: 0.00012309759321024524\n",
      "Loss: 0.00012302007631173227\n",
      "Loss: 0.00012294384407563424\n",
      "Loss: 0.00012286887229401986\n",
      "Loss: 0.00012279513728346357\n",
      "Loss: 0.0001227226158719622\n",
      "Loss: 0.0001226512853862615\n",
      "Loss: 0.00012258112363948423\n",
      "Loss: 0.0001225121089191713\n",
      "Loss: 0.00012244421997561353\n",
      "Loss: 0.00012237743601053736\n",
      "Loss: 0.00012231173666608856\n",
      "Loss: 0.000122247102014148\n",
      "Loss: 0.00012218351254591025\n",
      "Loss: 0.0001221209491617897\n",
      "Loss: 0.00012205939316156372\n",
      "Loss: 0.00012199882623481911\n",
      "Loss: 0.00012193923045164189\n",
      "Loss: 0.00012188058825356506\n",
      "Loss: 0.00012182288244476461\n",
      "Loss: 0.00012176609618348786\n",
      "Loss: 0.000121710212973714\n",
      "Loss: 0.0001216552166570438\n",
      "Loss: 0.00012160109140479381\n",
      "Loss: 0.00012154782171032235\n",
      "Loss: 0.00012149539238152327\n",
      "Loss: 0.0001214437885335647\n",
      "Loss: 0.00012139299558177301\n",
      "Loss: 0.00012134299923473607\n",
      "Loss: 0.00012129378548757405\n",
      "Loss: 0.00012124534061537844\n",
      "Loss: 0.0001211976511668417\n",
      "Loss: 0.00012115070395802754\n",
      "Loss: 0.00012110448606632319\n",
      "Loss: 0.00012105898482453038\n",
      "Loss: 0.00012101418781511438\n",
      "Loss: 0.00012097008286460948\n",
      "Loss: 0.00012092665803814523\n",
      "Loss: 0.00012088390163412812\n",
      "Loss: 0.00012084180217905795\n",
      "Loss: 0.00012080034842245736\n",
      "Loss: 0.00012075952933195641\n",
      "Loss: 0.00012071933408847345\n",
      "Loss: 0.00012067975208153224\n",
      "Loss: 0.00012064077290468453\n",
      "Loss: 0.00012060238635106298\n",
      "Loss: 0.00012056458240902272\n",
      "Loss: 0.00012052735125790507\n",
      "Loss: 0.00012049068326390235\n",
      "Loss: 0.00012045456897602168\n",
      "Loss: 0.00012041899912214365\n",
      "Loss: 0.00012038396460518847\n",
      "Loss: 0.00012034945649936218\n",
      "Loss: 0.00012031546604649868\n",
      "Loss: 0.0001202819846524993\n",
      "Loss: 0.00012024900388383591\n",
      "Loss: 0.00012021651546416574\n",
      "Loss: 0.0001201845112709974\n",
      "Loss: 0.0001201529833324646\n",
      "Loss: 0.00012012192382415494\n",
      "Loss: 0.0001200913250660297\n",
      "Loss: 0.00012006117951939872\n",
      "Loss: 0.00012003147978398335\n",
      "Loss: 0.00012000221859504444\n",
      "Loss: 0.00011997338882057037\n",
      "Loss: 0.00011994498345853286\n",
      "Loss: 0.0001199169956342186\n",
      "Loss: 0.00011988941859759887\n",
      "Loss: 0.00011986224572079018\n",
      "Loss: 0.00011983547049555103\n",
      "Loss: 0.00011980908653083602\n",
      "Loss: 0.00011978308755042572\n",
      "Loss: 0.00011975746739058937\n",
      "Loss: 0.0001197322199978195\n",
      "Loss: 0.00011970733942659574\n",
      "Loss: 0.00011968281983722413\n",
      "Loss: 0.00011965865549370552\n",
      "Loss: 0.00011963484076166329\n",
      "Loss: 0.00011961137010631917\n",
      "Loss: 0.00011958823809050258\n",
      "Loss: 0.00011956543937271\n",
      "Loss: 0.00011954296870522533\n",
      "Loss: 0.00011952082093224657\n",
      "Loss: 0.00011949899098808874\n",
      "Loss: 0.00011947747389540631\n",
      "Loss: 0.00011945626476346354\n",
      "Loss: 0.00011943535878643033\n",
      "Loss: 0.00011941475124173686\n",
      "Loss: 0.00011939443748845597\n",
      "Loss: 0.00011937441296570212\n",
      "Loss: 0.0001193546731910894\n",
      "Loss: 0.00011933521375922337\n",
      "Loss: 0.00011931603034020015\n",
      "Loss: 0.00011929711867816473\n",
      "Loss: 0.0001192784745898963\n",
      "Loss: 0.00011926009396340064\n",
      "Loss: 0.0001192419727565734\n",
      "Loss: 0.00011922410699584302\n",
      "Loss: 0.00011920649277489551\n",
      "Loss: 0.00011918912625337605\n",
      "Loss: 0.00011917200365566384\n",
      "Loss: 0.00011915512126962879\n",
      "Loss: 0.00011913847544545355\n",
      "Loss: 0.00011912206259446157\n",
      "Loss: 0.00011910587918796022\n",
      "Loss: 0.00011908992175613345\n",
      "Loss: 0.00011907418688693456\n",
      "Loss: 0.00011905867122502176\n",
      "Loss: 0.00011904337147069487\n",
      "Loss: 0.00011902828437886983\n",
      "Loss: 0.00011901340675807719\n",
      "Loss: 0.00011899873546945773\n",
      "Loss: 0.00011898426742580838\n",
      "Loss: 0.00011896999959063564\n",
      "Loss: 0.0001189559289772146\n",
      "Loss: 0.00011894205264768917\n",
      "Loss: 0.00011892836771218382\n",
      "Loss: 0.00011891487132792464\n",
      "Loss: 0.00011890156069838455\n",
      "Loss: 0.00011888843307245826\n",
      "Loss: 0.00011887548574362335\n",
      "Loss: 0.00011886271604915167\n",
      "Loss: 0.0001188501213693122\n",
      "Loss: 0.00011883769912660818\n",
      "Loss: 0.00011882544678501482\n",
      "Loss: 0.00011881336184923623\n",
      "Loss: 0.00011880144186399002\n",
      "Loss: 0.00011878968441328477\n",
      "Loss: 0.00011877808711972507\n",
      "Loss: 0.00011876664764383225\n",
      "Loss: 0.00011875536368336825\n",
      "Loss: 0.00011874423297268635\n",
      "Loss: 0.0001187332532820743\n",
      "Loss: 0.00011872242241713809\n",
      "Loss: 0.00011871173821817475\n",
      "Loss: 0.00011870119855956767\n",
      "Loss: 0.0001186908013491839\n",
      "Loss: 0.00011868054452780691\n",
      "Loss: 0.00011867042606855095\n",
      "Loss: 0.00011866044397630362\n",
      "Loss: 0.00011865059628717867\n",
      "Loss: 0.00011864088106797416\n",
      "Loss: 0.00011863129641564184\n",
      "Loss: 0.00011862184045677365\n",
      "Loss: 0.00011861251134708412\n",
      "Loss: 0.00011860330727092122\n",
      "Loss: 0.00011859422644076964\n",
      "Loss: 0.00011858526709676867\n",
      "Loss: 0.00011857642750625189\n",
      "Loss: 0.00011856770596327394\n",
      "Loss: 0.00011855910078815839\n",
      "Loss: 0.00011855061032705407\n",
      "Loss: 0.00011854223295150968\n",
      "Loss: 0.00011853396705802182\n",
      "Loss: 0.00011852581106763624\n",
      "Loss: 0.00011851776342552423\n",
      "Loss: 0.00011850982260058045\n",
      "Loss: 0.00011850198708502606\n",
      "Loss: 0.00011849425539401673\n",
      "Loss: 0.00011848662606526403\n",
      "Loss: 0.00011847909765865884\n",
      "Loss: 0.00011847166875589707\n",
      "Loss: 0.0001184643379601237\n",
      "Loss: 0.00011845710389558206\n",
      "Loss: 0.00011844996520724977\n",
      "Loss: 0.00011844292056051128\n",
      "Loss: 0.00011843596864081814\n",
      "Loss: 0.00011842910815335066\n",
      "Loss: 0.00011842233782270999\n",
      "Loss: 0.00011841565639258521\n",
      "Loss: 0.00011840906262544625\n",
      "Loss: 0.00011840255530223887\n",
      "Loss: 0.00011839613322208829\n",
      "Loss: 0.00011838979520198912\n",
      "Loss: 0.00011838354007653324\n",
      "Loss: 0.00011837736669760732\n",
      "Loss: 0.00011837127393412332\n",
      "Loss: 0.00011836526067174359\n",
      "Loss: 0.00011835932581260831\n",
      "Loss: 0.00011835346827506804\n",
      "Loss: 0.00011834768699342574\n",
      "Loss: 0.00011834198091768182\n",
      "Loss: 0.00011833634901328118\n",
      "Loss: 0.00011833079026086231\n",
      "Loss: 0.00011832530365602752\n",
      "Loss: 0.00011831988820908906\n",
      "Loss: 0.00011831454294484262\n",
      "Loss: 0.00011830926690233776\n",
      "Loss: 0.00011830405913464954\n",
      "Loss: 0.00011829891870866268\n",
      "Loss: 0.00011829384470483971\n",
      "Loss: 0.00011828883621702273\n",
      "Loss: 0.0001182838923522062\n",
      "Loss: 0.0001182790122303471\n",
      "Loss: 0.00011827419498414958\n",
      "Loss: 0.0001182694397588669\n",
      "Loss: 0.00011826474571211182\n",
      "Loss: 0.00011826011201364747\n",
      "Loss: 0.00011825553784522266\n",
      "Loss: 0.00011825102240035675\n",
      "Loss: 0.00011824656488418182\n",
      "Loss: 0.00011824216451324207\n",
      "Loss: 0.00011823782051532852\n",
      "Loss: 0.00011823353212930385\n",
      "Loss: 0.00011822929860492656\n",
      "Loss: 0.00011822511920268735\n",
      "Loss: 0.00011822099319363556\n",
      "Loss: 0.00011821691985923575\n",
      "Loss: 0.00011821289849117233\n",
      "Loss: 0.00011820892839124042\n",
      "Loss: 0.00011820500887114592\n",
      "Loss: 0.00011820113925238031\n",
      "Loss: 0.00011819731886606113\n",
      "Loss: 0.0001181935470527899\n",
      "Loss: 0.00011818982316250493\n",
      "Loss: 0.00011818614655433899\n",
      "Loss: 0.0001181825165964748\n",
      "Loss: 0.00011817893266602469\n",
      "Loss: 0.00011817539414886933\n",
      "Loss: 0.00011817190043955288\n",
      "Loss: 0.00011816845094112773\n",
      "Loss: 0.00011816504506504046\n",
      "Loss: 0.00011816168223100235\n",
      "Loss: 0.00011815836186686236\n",
      "Loss: 0.00011815508340848855\n",
      "Loss: 0.00011815184629964092\n",
      "Loss: 0.00011814864999186717\n",
      "Loss: 0.0001181454939443631\n",
      "Loss: 0.00011814237762388615\n",
      "Loss: 0.0001181393005046166\n",
      "Loss: 0.0001181362620680652\n",
      "Loss: 0.00011813326180295612\n",
      "Loss: 0.00011813029920511963\n",
      "Loss: 0.0001181273737773876\n",
      "Loss: 0.00011812448502949108\n",
      "Loss: 0.00011812163247795308\n",
      "Loss: 0.0001181188156459973\n",
      "Loss: 0.00011811603406343921\n",
      "Loss: 0.0001181132872665931\n",
      "Loss: 0.00011811057479817979\n",
      "Loss: 0.00011810789620722314\n",
      "Loss: 0.00011810525104896701\n",
      "Loss: 0.00011810263888478035\n",
      "Loss: 0.00011810005928206272\n",
      "Loss: 0.00011809751181416306\n",
      "Loss: 0.00011809499606028647\n",
      "Loss: 0.00011809251160541653\n",
      "Loss: 0.00011809005804022192\n",
      "Loss: 0.00011808763496097948\n",
      "Loss: 0.0001180852419694866\n",
      "Loss: 0.0001180828786729935\n",
      "Loss: 0.00011808054468410523\n",
      "Loss: 0.00011807823962072511\n",
      "Loss: 0.00011807596310595645\n",
      "Loss: 0.00011807371476804384\n",
      "Loss: 0.00011807149424029444\n",
      "Loss: 0.00011806930116099372\n",
      "Loss: 0.00011806713517335529\n",
      "Loss: 0.00011806499592542804\n",
      "Loss: 0.0001180628830700402\n",
      "Loss: 0.00011806079626472782\n",
      "Loss: 0.0001180587351716598\n",
      "Loss: 0.00011805669945758615\n",
      "Loss: 0.00011805468879375828\n",
      "Loss: 0.00011805270285586819\n",
      "Loss: 0.00011805074132398799\n",
      "Loss: 0.00011804880388250755\n",
      "Loss: 0.00011804689022007263\n",
      "Loss: 0.00011804500002951652\n",
      "Loss: 0.00011804313300781302\n",
      "Loss: 0.00011804128885600757\n",
      "Loss: 0.00011803946727916253\n",
      "Loss: 0.000118037667986306\n",
      "Loss: 0.00011803589069036434\n",
      "Loss: 0.00011803413510811354\n",
      "Loss: 0.0001180324009601257\n",
      "Loss: 0.00011803068797071255\n",
      "Loss: 0.0001180289958678741\n",
      "Loss: 0.00011802732438324707\n",
      "Loss: 0.0001180256732520502\n",
      "Loss: 0.00011802404221304085\n",
      "Loss: 0.00011802243100845327\n",
      "Loss: 0.00011802083938396286\n",
      "Loss: 0.00011801926708863109\n",
      "Loss: 0.00011801771387486011\n",
      "Loss: 0.00011801617949834294\n",
      "Loss: 0.0001180146637180174\n",
      "Loss: 0.0001180131662960274\n",
      "Loss: 0.00011801168699766995\n",
      "Loss: 0.00011801022559135861\n",
      "Loss: 0.00011800878184856668\n",
      "Loss: 0.00011800735554380734\n",
      "Loss: 0.00011800594645456802\n",
      "Loss: 0.00011800455436128034\n",
      "Loss: 0.00011800317904728129\n",
      "Loss: 0.00011800182029876209\n",
      "Loss: 0.00011800047790475118\n",
      "Loss: 0.00011799915165703782\n",
      "Loss: 0.00011799784135017471\n",
      "Loss: 0.0001179965467814106\n",
      "Loss: 0.00011799526775066628\n",
      "Loss: 0.00011799400406049168\n",
      "Loss: 0.0001179927555160385\n",
      "Loss: 0.00011799152192501308\n",
      "Loss: 0.00011799030309764685\n",
      "Loss: 0.00011798909884666295\n",
      "Loss: 0.00011798790898723801\n",
      "Loss: 0.00011798673333697446\n",
      "Loss: 0.00011798557171586001\n",
      "Loss: 0.00011798442394624031\n",
      "Loss: 0.00011798328985278419\n",
      "Loss: 0.00011798216926245016\n",
      "Loss: 0.00011798106200446114\n",
      "Loss: 0.00011797996791026683\n",
      "Loss: 0.00011797888681351859\n",
      "Loss: 0.00011797781855003426\n",
      "Loss: 0.00011797676295777157\n",
      "Loss: 0.00011797571987680147\n",
      "Loss: 0.00011797468914927625\n",
      "Loss: 0.0001179736706193986\n",
      "Loss: 0.00011797266413339997\n",
      "Loss: 0.00011797166953950632\n",
      "Loss: 0.00011797068668791981\n",
      "Loss: 0.0001179697154307848\n",
      "Loss: 0.00011796875562215971\n",
      "Loss: 0.00011796780711799789\n",
      "Loss: 0.00011796686977612291\n",
      "Loss: 0.00011796594345619153\n",
      "Loss: 0.00011796502801968454\n",
      "Loss: 0.00011796412332986859\n",
      "Loss: 0.0001179632292517817\n",
      "Loss: 0.00011796234565220558\n",
      "Loss: 0.00011796147239963798\n",
      "Loss: 0.00011796060936428256\n",
      "Loss: 0.00011795975641800598\n",
      "Loss: 0.0001179589134343382\n",
      "Loss: 0.00011795808028842944\n",
      "Loss: 0.00011795725685704302\n",
      "Loss: 0.00011795644301853052\n",
      "Loss: 0.00011795563865280147\n",
      "Loss: 0.0001179548436413166\n",
      "Loss: 0.00011795405786705651\n",
      "Loss: 0.00011795328121450562\n",
      "Loss: 0.0001179525135696305\n"
     ]
    }
   ],
   "source": [
    "NN = NeuralNetwork()\n",
    "for i in range(50000):\n",
    "    if(i % 100 == 0):\n",
    "        print(\"Loss: \"+ str(np.mean(np.square(y -NN.feedforward(X)))))\n",
    "    NN.train(X,y)9 nhlh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBBw3UPWGLvT",
    "outputId": "cd7fc802-934b-4de4-ca50-596174bd7708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual output: [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted output: [[0.90548211]\n",
      " [0.87189349]\n",
      " [0.89127719]]\n",
      "Loss:0.00011795175481986653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \"+str(X))\n",
    "print(\"Actual output: \" + str(y))\n",
    "print(\"Predicted output: \" + str(NN.feedforward(X)))\n",
    "print(\"Loss: \"+ str(np.mean(np.square(y -NN.feedforward(X)))))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "backpropagation.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "dcacb0086e9a4f4eabd41c33bf4faac5ea0a3337ed3f5eff0680afa930572c04"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
